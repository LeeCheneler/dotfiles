# Claude Code Setup ‚Äî Implementation Spec v2

> **Purpose:** Complete replacement of Lee's `~/.dotfiles/config/claude/` setup.
> This document is the single source of truth for Claude Code to execute against.
> Every decision has been made. All content is defined. No ambiguity remains.
>
> **How to use this:** Work through the implementation plan at the bottom.
> Create each file with the exact content specified. The directory structure,
> file names, and content are all final.

---

## Directory Structure

### Global (in dotfiles repo, symlinked to ~/.claude/)

```
~/.dotfiles/config/claude/
‚îú‚îÄ‚îÄ CLAUDE.md
‚îú‚îÄ‚îÄ settings.json
‚îú‚îÄ‚îÄ commands/
‚îÇ   ‚îú‚îÄ‚îÄ workflow.md
‚îÇ   ‚îú‚îÄ‚îÄ commit.md
‚îÇ   ‚îú‚îÄ‚îÄ pr.md
‚îÇ   ‚îú‚îÄ‚îÄ review.md
‚îÇ   ‚îú‚îÄ‚îÄ test.md
‚îÇ   ‚îú‚îÄ‚îÄ write-tests.md
‚îÇ   ‚îú‚îÄ‚îÄ plan.md
‚îÇ   ‚îú‚îÄ‚îÄ init-project.md
‚îÇ   ‚îî‚îÄ‚îÄ refresh-project.md
‚îú‚îÄ‚îÄ skills/
‚îÇ   ‚îú‚îÄ‚îÄ coding-standards/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ SKILL.md
‚îÇ   ‚îú‚îÄ‚îÄ test-conventions/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ SKILL.md
‚îÇ   ‚îî‚îÄ‚îÄ commit-conventions/
‚îÇ       ‚îî‚îÄ‚îÄ SKILL.md
‚îú‚îÄ‚îÄ agents/
‚îÇ   ‚îú‚îÄ‚îÄ researcher.md
‚îÇ   ‚îú‚îÄ‚îÄ planner.md
‚îÇ   ‚îú‚îÄ‚îÄ coder.md
‚îÇ   ‚îú‚îÄ‚îÄ reviewer.md
‚îÇ   ‚îú‚îÄ‚îÄ test-writer.md
‚îÇ   ‚îî‚îÄ‚îÄ test-runner.md
‚îî‚îÄ‚îÄ docs/
    ‚îú‚îÄ‚îÄ ARCHITECTURE.md
    ‚îú‚îÄ‚îÄ WORKFLOWS.md
    ‚îî‚îÄ‚îÄ CONVENTIONS.md
```

### Symlinks (scripts/ai.sh)

```bash
ln -sf ~/.dotfiles/config/claude/CLAUDE.md ~/.claude/CLAUDE.md
ln -sf ~/.dotfiles/config/claude/settings.json ~/.claude/settings.json
ln -sf ~/.dotfiles/config/claude/commands ~/.claude/commands
ln -sf ~/.dotfiles/config/claude/skills ~/.claude/skills
ln -sf ~/.dotfiles/config/claude/agents ~/.claude/agents
```

Remove `bin/init-claude` ‚Äî replaced by `/init-project` command.

---

## File Contents

### CLAUDE.md (Global)

```markdown
# Global Instructions

You are working with Lee, a principal engineer. Lee works across fullstack
TypeScript/Node (React, Next.js), AWS (Terraform, serverless, Aurora Postgres),
and game engine programming. Adapt to whatever project you're in.

## Core Principles

1. **KISS.** Keep it simple. Small functions, simple modules, clear intent.
   If a solution feels clever, it's probably wrong. Prefer the boring,
   obvious approach.

2. **Read before writing.** Always explore the relevant code before making
   changes. Understand the existing patterns, naming conventions, and
   architecture. Match the codebase ‚Äî don't introduce new patterns unless
   explicitly asked.

3. **Purity without dogma.** Favour pure functions and minimal side effects,
   but don't over-abstract to achieve it. Pragmatism over purity.

4. **Don't abstract too early.** Functions can be similar by happenstance.
   Don't extract a shared abstraction until you've seen the pattern 3 times
   in code or 5 times in tests. Premature abstraction is worse than
   duplication.

5. **Small, atomic changes.** Each commit should do one thing. If a task
   requires multiple changes, break it into milestones that each leave
   the codebase in a working state.

6. **Let errors bubble.** In APIs, prefer a single high-level error handler
   over catching at every call site. Keep the coding surface simple and
   error handling consistent. Don't swallow errors.

7. **Match the project.** When creating new files, follow existing project
   conventions. If a repo uses camelCase filenames, use camelCase. If there's
   no precedent, favour kebab-case. Always check before assuming.

8. **Ambiguity resolution.** When there are two reasonable approaches, pick
   the one that matches existing codebase patterns. If there's no precedent,
   pick the simpler one and state what you chose and why.

## Workflow System

Use `/workflow <task>` to auto-route, or invoke commands directly:

| Command                 | Purpose                                           |
| ----------------------- | ------------------------------------------------- |
| `/workflow <task>`      | Auto-route to Simple or Pipeline workflow         |
| `/commit`               | Conventional commit with guards                   |
| `/pr`                   | Create pull request                               |
| `/review [target]`      | Code review                                       |
| `/test [scope]`         | Run tests                                         |
| `/write-tests [target]` | Generate tests                                    |
| `/plan <task>`          | Research + plan only (no execution)               |
| `/init-project`         | Generate project CLAUDE.md from codebase analysis |
| `/refresh-project`      | Update existing project CLAUDE.md                 |

## Security Rules

### Deletion Safety

- NEVER run `rm -rf` on any path that resolves outside the current project root
- For any `rm` command affecting more than 3 files, list what will be deleted
  and ask for confirmation before proceeding
- Prefer `git clean -fd` over manual `rm` for cleaning build artifacts

### Git Safety

- NEVER force-push to main, master, or develop branches
- NEVER commit .env files, secrets, credentials, API keys, or tokens
- NEVER reference Claude, AI, or any AI tool in commit messages or PR descriptions
- Always run `git diff --staged` and present a summary before committing
- NEVER rebase shared/protected branches without explicit permission

### Destructive Operation Gate

Any operation that deletes more than 3 files, drops a database table, modifies
CI/CD config, or changes infrastructure (terraform) requires presenting a
summary of what will change and getting explicit confirmation before proceeding.

### Secrets

- NEVER read, display, or log the contents of .env files or any file
  containing secrets or credentials
- If you encounter a secret in code, flag it as a security issue

## Compaction Guidance

When compacting context, ALWAYS preserve:

1. The current plan.md contents (milestones, progress, current state)
2. Which milestone you're currently working on and its gate mode
3. Any deviations from the plan noted so far
4. The project CLAUDE.md contents
5. Any gotchas discovered during this session

Deprioritize: file contents already committed, completed milestone details,
exploratory reads that didn't yield useful information.

## Communication Style

- Be direct and concise. Skip preamble.
- When presenting options, lead with your recommendation and why.
- Use code blocks for anything more than a single line of code.
- Don't apologize for previous responses or over-explain.
- If something is ambiguous, state your assumption and proceed.
  Don't block on clarification for small decisions.
- Don't ask for permission to do things that are obviously part of the task.
```

---

### settings.json

```json
{
  "permissions": {
    "deny": [
      "Read(./.env)",
      "Read(./.env.*)",
      "Read(./secrets/**)",
      "Read(./**/*credentials*)",
      "Read(./**/*secret*)",
      "Bash(rm -rf /)",
      "Bash(rm -rf ~)",
      "Bash(rm -rf $HOME)"
    ],
    "ask": [
      "Bash(git push --force*)",
      "Bash(git push -f*)",
      "Bash(git rebase*)",
      "Bash(git reset --hard*)",
      "Bash(rm -rf *)",
      "Bash(rm -r *)",
      "Bash(terraform apply*)",
      "Bash(terraform destroy*)",
      "Bash(aws *)"
    ],
    "allow": [
      "Bash(git status*)",
      "Bash(git diff*)",
      "Bash(git log*)",
      "Bash(git branch*)",
      "Bash(git add*)",
      "Bash(git commit*)",
      "Bash(git checkout*)",
      "Bash(git switch*)",
      "Bash(git stash*)",
      "Bash(git fetch*)",
      "Bash(git pull*)",
      "Bash(git push)",
      "Bash(git push origin*)",
      "Bash(npm *)",
      "Bash(npx *)",
      "Bash(pnpm *)",
      "Bash(yarn *)",
      "Bash(pip *)",
      "Bash(cargo *)",
      "Bash(make *)",
      "Bash(node *)",
      "Bash(deno *)",
      "Bash(python *)",
      "Bash(tsc *)",
      "Bash(cat *)",
      "Bash(head *)",
      "Bash(tail *)",
      "Bash(wc *)",
      "Bash(grep *)",
      "Bash(rg *)",
      "Bash(fd *)",
      "Bash(find *)",
      "Bash(ls *)",
      "Bash(tree *)",
      "Bash(mkdir *)",
      "Bash(cp *)",
      "Bash(mv *)",
      "Bash(touch *)",
      "Bash(chmod *)",
      "Bash(echo *)",
      "Bash(curl *)",
      "Bash(jq *)",
      "Bash(sed *)",
      "Bash(awk *)",
      "Bash(sort *)",
      "Bash(uniq *)",
      "Bash(diff *)",
      "Bash(gh *)"
    ]
  },
  "hooks": {
    "PreToolUse": [
      {
        "matcher": "Bash",
        "hooks": [
          {
            "type": "prompt",
            "prompt": "The user is about to run a bash command. Check if it: (1) contains 'rm -rf' or 'rm -r' targeting a path outside the current project directory ($CLAUDE_PROJECT_DIR), (2) force-pushes to main/master/develop branches, (3) runs terraform destroy without a targeted resource, or (4) drops database tables. If dangerous, set decision to 'block' with a clear reason. If safe, set decision to 'approve'."
          }
        ]
      }
    ],
    "Stop": [
      {
        "matcher": "",
        "hooks": [
          {
            "type": "command",
            "command": "osascript -e 'display notification \"Task completed\" with title \"Claude Code\"' 2>/dev/null || true"
          }
        ]
      }
    ]
  }
}
```

---

### commands/workflow.md

```markdown
Evaluate the task and route it to the most appropriate workflow.

## Routing Criteria

### SIMPLE ‚Äî Use when ALL of these are true:

- Single concern (one file, one function, one doc, one config change)
- No ambiguity about what needs to change
- No cross-cutting concerns across multiple modules
- Estimated effort: under 15 minutes

**Flow:** Read the relevant code ‚Üí make the edit(s) ‚Üí run tests if they
exist for the affected area ‚Üí /commit.

### PIPELINE ‚Äî Use when ANY of these are true:

- Multiple files need coordinated changes
- Requires exploring the codebase first to understand the landscape
- Has clear milestones (e.g., "add API endpoint + tests + docs")
- Involves refactoring, migration, or feature implementation
- Estimated effort: 15 minutes to 2 hours, or 3-20 files affected

**Flow:**

1. Research: explore relevant code, docs, tests, dependencies. Identify
   blast radius and risks. Write findings to `docs/work/<slug>/research.md`.
2. Plan: break into numbered milestones, each = one atomic commit. Include
   gate criteria, commit messages, risks. Penultimate milestone: extract ADRs.
   Final milestone: delete the work directory. Write to
   `docs/work/<slug>/plan.md`. Ask what gate mode to use (continuous or gated).
3. Present plan. Wait for approval before executing.
4. Execute milestones sequentially. After each milestone: run tests, update
   plan.md, /commit. Check-in behavior depends on the gate mode:
   - **continuous**: report status and continue unless stopped
   - **gated**: report status and wait for explicit go-ahead
     Individual milestones can override the default gate mode.
5. Finalize: run full test suite, propose any CLAUDE.md learnings (present
   diff for approval), extract ADRs, delete work directory, /pr.

## After routing, announce:

"**Routing to [SIMPLE|PIPELINE] because:** <one-line reason>"

The user can override: "No, use pipeline for this." Always respect overrides.

## Task:

$ARGUMENTS
```

---

### commands/commit.md

```markdown
Create a clean, conventional commit for the current changes.

## Process

1. Run `git diff --staged`. If nothing is staged, run `git diff` and stage
   the relevant files. Ask if it's ambiguous which files to include.

2. Analyze the diff:
   - What changed and why
   - How many files affected
   - Red flags: secrets, .env files, debug code (console.log, debugger
     statements), large binaries, generated files, TODO/FIXME additions

3. If red flags found, report them and ask whether to proceed.

4. Generate a conventional commit message:
   - Format: `<type>(<scope>): <description>`
   - Types: feat, fix, refactor, test, docs, chore, perf, ci, style, build
   - Scope: derive from the primary area of change
   - Description: imperative mood, lowercase, no period, under 72 chars
   - Body (if the change is complex): concise bullet points on what and why
   - Footer: reference ticket/issue numbers if mentioned in the conversation
   - NEVER mention Claude, AI, or any AI tool anywhere in the commit

5. Present the commit message and a brief summary of what's being committed.
   Ask for confirmation or edits.

6. Commit.

## Guards

- REFUSE to commit if .env, credentials, secrets, or API keys are staged
- WARN if committing generated/build files (dist/, build/, node_modules/)
- WARN if commit is unusually large (more than 10 files) ‚Äî suggest splitting
- WARN if tests are failing in the affected area (flag it, don't block)
```

---

### commands/pr.md

```markdown
Create a pull request for the current branch.

## Process

1. Determine target branch:
   - Default: main or master (whichever exists)
   - If the branch was created from develop, target develop
   - Ask if ambiguous

2. Pre-flight checks:
   - `git log <target>..HEAD --oneline` to see commits in this PR
   - Run the project's test suite
   - `git fetch && git log HEAD..<target>` to check if behind target

3. Check if a PR template exists in the repo:
   - Look for `.github/pull_request_template.md` or `.github/PULL_REQUEST_TEMPLATE.md`
   - If a template exists, follow its structure exactly
   - If no template exists, generate a PR description with:
     - **Title:** derive from branch name or commit history, imperative mood
     - **What:** what changed, grouped by area (not a raw file list)
     - **Why:** the context and motivation for the change
     - **Where:** key areas of the codebase affected
     - **Testing:** what was tested, how to verify, manual steps if needed
     - **Notes:** breaking changes, migration steps, deployment considerations
   - If `docs/work/<slug>/plan.md` exists, reference relevant context from it

4. NEVER mention Claude, AI, or any AI tool in the PR description.

5. Create PR: `gh pr create --title "..." --body "..." --base <target>`

6. Present the PR URL.

## Guards

- REFUSE to create PR if tests are failing (unless explicitly overridden)
- WARN if PR is very large (more than 500 lines changed) ‚Äî suggest splitting
- WARN if branch is behind target ‚Äî suggest rebasing first
- WARN if there are uncommitted changes ‚Äî suggest committing or stashing
```

---

### commands/review.md

```markdown
Review code changes for quality, patterns, and potential issues.

## Input

Accept one of: a PR number, a branch name, a diff range, or "current changes".
Default to uncommitted changes if nothing is specified.

## Process

1. Get the diff:
   - PR number: `gh pr diff <number>`
   - Branch: `git diff main...<branch>`
   - Current: `git diff`

2. Review against these dimensions (skip anything covered by automated
   linting/formatting ‚Äî don't review what tooling should catch):

   - **Correctness:** Logic errors, edge cases, off-by-one errors,
     null/undefined handling, race conditions
   - **Security:** Injection risks, auth bypass, secrets in code,
     unsafe deserialization, exposed internals
   - **Performance:** N+1 queries, unnecessary allocations, missing indexes,
     redundant re-renders, expensive operations in hot paths
   - **Simplicity:** Over-abstraction, premature generalization, unnecessary
     complexity, functions doing too much
   - **Tests:** Are changes covered by tests? Are tests testing behavior
     (not implementation)? Are mocks used only at boundaries? Any missing
     edge cases? Do test names describe expected behavior?
   - **Conventions:** Does it match the project's established patterns?

3. For each finding:
   - Severity: üî¥ Must fix | üü° Should fix | üü¢ Suggestion | üí≠ Nitpick
   - File and line reference
   - What the issue is
   - Suggested fix (with code if non-trivial)

4. Summary:
   - Overall assessment: Approve / Request changes / Needs discussion
   - Count of findings by severity
   - Highlight what's done well (not just problems)

## Arguments

$ARGUMENTS
```

---

### commands/test.md

```markdown
Run tests intelligently based on the project and context.

## Process

1. Detect test framework and runner:
   - Check package.json scripts (test, test:unit, test:e2e, test:integration)
   - Check for vitest.config, jest.config, playwright.config, pytest.ini, etc.
   - Check for Makefile test targets, cargo test, go test, etc.

2. Determine scope:
   - If $ARGUMENTS specifies files or patterns, run those
   - If there are uncommitted changes, run tests related to changed files
   - Otherwise, run the full suite

3. Run tests and present results:
   - On pass: concise summary (X passed in Ys)
   - On fail: for each failure show test name, assertion, and relevant
     code context
   - Never dump entire raw test output unless explicitly asked ‚Äî summarize

## Arguments

$ARGUMENTS
```

---

### commands/write-tests.md

```markdown
Generate tests for the specified code.

## Philosophy

- Test units of behavior, not units of code
- Each test should read as: given X, when Y, then Z
- Test names should describe the expected behavior in plain English
- Prefer realistic test data over contrived examples
- Treat mocking with general disdain ‚Äî mock only at boundaries (network
  with MSW, filesystem, external services). Never mock internal modules
- Don't extract shared test helpers until you've seen the same pattern
  5 times (rule of 5 in tests)
- Favour *.test.ts(x) over *.spec.ts(x) unless the project already uses spec

## Process

1. Identify what to test:
   - If $ARGUMENTS specifies a file or function, test that
   - If not, look at recent changes and suggest what needs tests

2. Analyze the code:
   - Public API surface (what consumers/callers use)
   - Edge cases and error paths
   - Integration points and boundaries
   - Existing test patterns in the project

3. Detect project test conventions:
   - Test file location (co-located vs **tests** vs test/)
   - Test framework and assertion style
   - Mocking patterns already in use
   - Naming conventions

4. Generate tests following project conventions:
   - Group by behavior/feature, not by function
   - Cover: happy path, edge cases, error handling
   - Use descriptive names: "should return 404 when user not found"
   - Keep each test independent and focused
   - Match the project's existing patterns exactly

5. Run the new tests to verify they pass.

## Arguments

$ARGUMENTS
```

---

### commands/plan.md

```markdown
Research the codebase and create an implementation plan. This is phases 1-2
of the Pipeline workflow, extracted as a standalone command for when you want
to plan without immediately executing.

## Process

1. **Research** the relevant areas of the codebase:
   - Find related code, tests, docs, config files
   - Understand the current architecture and patterns
   - Identify dependencies and blast radius
   - Write findings to `docs/work/<slug>/research.md`

2. **Plan** the implementation:
   - Break into numbered milestones (each = one atomic, testable commit)
   - For each milestone: steps, gate criteria, conventional commit message
   - Penultimate milestone: extract relevant ADRs to docs/decisions/
   - Final milestone: delete docs/work/<slug>/
   - Note risks, open questions, and alternatives considered
   - Write plan to `docs/work/<slug>/plan.md`

3. **Ask** the user what gate mode to use:
   - **continuous** (default): status update after each milestone, keep going
   - **gated**: pause after each milestone, wait for go-ahead
   - Individual milestones can override the default (useful for risky steps)

4. **Present** the plan for review.

The slug is derived from $ARGUMENTS (kebab-cased, e.g., "add-user-auth").

## Plan File Format
```

<!-- Working document. Will be deleted after ADRs are extracted. -->

# Plan: <title>

## Config

**Gate mode:** continuous|gated

## Context

<1-2 paragraphs: what we're doing and why>

## Research Summary

<Key findings ‚Äî link to research.md for full detail>

## Milestones

### Milestone 1: <title>

- [ ] Step 1.1: <description>
- [ ] Step 1.2: <description>
      **Gate:** <what must be true before proceeding>
      **Commit:** `<type>(<scope>): <description>`

### Milestone N-1: Extract ADRs

- [ ] Review work for architectural decisions worth documenting
- [ ] Write ADRs to docs/decisions/ following project's ADR format
      **Gate:** ADRs written and make sense standalone
      **Commit:** `docs: add ADRs for <feature>`

### Milestone N: Clean up

- [ ] Delete docs/work/<slug>/
      **Commit:** `chore: remove working docs for <slug>`

## Risks & Open Questions

- <risk or question>

## Deviations Log

<Updated during execution ‚Äî what changed from the original plan and why>

```
## Arguments
$ARGUMENTS
```

---

### commands/init-project.md

```markdown
Generate a world-class project-specific CLAUDE.md by deeply analyzing this
repository. The goal is to capture derived knowledge that saves Claude from
re-reading the entire project at the start of every session.

## Reading Order (highest signal first)

Work through these in order, reading the most information-dense sources first:

1. **README.md, CONTRIBUTING.md** ‚Äî intent, setup instructions, conventions
2. **docs/decisions/, docs/adrs/** ‚Äî architectural decisions and their context
3. **docs/*** ‚Äî domain knowledge, architecture guides, API docs
4. **Package files** (package.json, Cargo.toml, go.mod, requirements.txt, etc.)
   ‚Äî stack, scripts, dependencies
5. **Config files** (tsconfig, eslint/biome, prettier, terraform, docker, etc.)
   ‚Äî coding standards already enforced by tooling
6. **CI/CD config** (.github/workflows/, Jenkinsfile, etc.) ‚Äî what's tested,
   how it deploys
7. **Directory structure** (tree, 2 levels deep) ‚Äî module layout, naming
8. **Key entrypoints** (main/index files, route definitions, handler files)
   ‚Äî architecture in practice
9. **Test setup** (test config, a few example test files) ‚Äî testing patterns,
   framework, structure, conventions

## Output

Create a CLAUDE.md at the project root with this structure:
```

<!-- Generated by /init-project on YYYY-MM-DD. Run /refresh-project to update. -->

# Project: <n>

## Overview

<What this project does, its purpose, key domain concepts. 2-3 sentences.>

## Stack

<Detected tech stack with versions where relevant. Be specific.>

## Key Commands

- **Install:** `<command>`
- **Build:** `<command>`
- **Test:** `<command>` (framework: <n>, location: <pattern>)
- **Lint:** `<command>`
- **Dev:** `<command>`
- **Deploy:** `<command or process description>`

## Architecture

<High-level description of how the project is structured ‚Äî modules, layers,
data flow. Derived from directory structure and entrypoint analysis. Keep it
concise but complete enough that someone (or Claude) can orient quickly.>

## Conventions

<Detected patterns that must be followed: naming conventions, file structure,
import style, error handling approach, state management patterns, API patterns.
Be specific ‚Äî "functions use camelCase, files use kebab-case, React components
use PascalCase" not "follow standard conventions".>

## Testing Patterns

<Test framework, assertion style, mocking approach (note: mock only at
boundaries), file naming (*.test.ts vs *.spec.ts), co-located vs separate,
any test utilities or helpers, how to run subsets of tests.>

## Key Decisions

<Summary of relevant ADRs or architectural decisions found in docs. Link to
the actual ADR files so they can be read in full if needed.>

## Gotchas

<Non-obvious things about this project ‚Äî unusual patterns, things that look
wrong but are intentional, known sharp edges, common mistakes.>

## Notes

<Anything else relevant ‚Äî deployment quirks, environment setup requirements,
external service dependencies, etc.>

```
Do NOT generate a thin, generic CLAUDE.md. Every section should contain
specific, actionable information derived from actually reading the codebase.
If a section has nothing meaningful to say, omit it rather than filling it
with generic advice.
```

---

### commands/refresh-project.md

```markdown
Update the existing project CLAUDE.md without regenerating from scratch.
Preserves manual additions while updating sections where the project has
drifted.

## Process

1. Read the current CLAUDE.md and note the generation date from the comment
   at the top.

2. Scan the project for changes that might affect the CLAUDE.md:
   - New or removed dependencies (package.json, lock files)
   - New modules, directories, or significant files
   - Changed config files (tsconfig, eslint, CI/CD)
   - New ADRs or documentation
   - Changed test setup or patterns
   - Changed build/dev/deploy commands

3. Compare current project state against what's documented in CLAUDE.md.

4. Propose targeted updates as a diff ‚Äî show what would change and why.
   Clearly distinguish between auto-generated sections being updated and
   manually-added content being preserved.

5. Present the diff for approval before writing.

6. If approved, update the CLAUDE.md and refresh the generation date comment.

## Key rule

Never remove or modify content that appears to have been manually added
(i.e., content not matching the /init-project template structure). When in
doubt, ask.

## Arguments

$ARGUMENTS
```

---

### skills/coding-standards/SKILL.md

```markdown
---
description: "Apply when writing, editing, or reviewing code in any language.
  Covers naming, structure, error handling, and code quality standards."
---

# Coding Standards

## General Principles

- **KISS.** Keep functions small and focused. Each function does one thing.
  If a function needs a comment explaining what it does, it should probably
  be split or renamed.
- **Purity.** Favour pure functions and minimize side effects. But don't
  over-abstract to achieve purity ‚Äî pragmatism wins.
- **No premature abstraction.** Don't extract a shared function or component
  until you've seen the same pattern 3 times (rule of 3). Duplication is
  cheaper than the wrong abstraction.
- **Simple modules.** Each module should have a clear, single responsibility.
  Avoid god modules that do everything.

## TypeScript Specific

- **Leverage the type system.** Use types to make invalid states
  unrepresentable. Prefer discriminated unions over boolean flags.
- **Don't destructure function parameters.** Use `(props: Props) => ...`
  not `({ id }: Props) => ...`. This preserves the type name in signatures,
  makes refactoring easier, and is clearer when functions have many params.
- **Let errors bubble.** In APIs, prefer a single high-level error boundary
  over catching at every call site. Catch at the top, let errors propagate
  naturally. This keeps the coding surface simpler and error handling
  consistent.

## Naming & Files

- **File naming:** kebab-case for all files unless the project uses a
  different convention. Always check existing files first and match.
  Well-known files (README.md, CONTRIBUTING.md, Dockerfile) keep their
  standard names.
- **Match the project.** Before creating any new file, check how existing
  files are named, structured, and organized. Follow the established pattern
  exactly, even if you'd prefer a different approach.

## Error Handling

- Don't swallow errors silently. Either handle them meaningfully or let
  them propagate.
- In API layers, use a centralized error handler rather than try/catch at
  every endpoint.
- Log errors with enough context to debug them (what was being attempted,
  what input caused it).
```

---

### skills/test-conventions/SKILL.md

```markdown
---
description: "Apply when writing, generating, or reviewing tests in any
  language. Covers test philosophy, structure, naming, and quality standards."
---

# Test Conventions

## Philosophy

- **Test behavior, not implementation.** Tests should verify what the code
  does from the consumer's perspective, not how it does it internally.
  If you refactor the internals and the behavior hasn't changed, tests
  should still pass.
- **Treat mocking with disdain.** Mock only at boundaries: network calls
  (use MSW or equivalent), filesystem, external services. Never mock
  internal modules or functions ‚Äî if you need to mock an internal thing
  to test another internal thing, your design probably needs work.
- **No premature test abstraction.** Don't extract shared test helpers or
  fixtures until you've seen the same pattern 5 times (rule of 5). Test
  code is allowed to be a bit repetitive if it makes each test clear and
  independent.
- **Write tests, don't obsess about order.** Test coverage matters.
  Whether you write tests before or after the implementation is a per-task
  judgement call, not a religious rule.

## Structure

- Favour `*.test.ts(x)` over `*.spec.ts(x)` unless the project already
  uses spec files ‚Äî then match the project.
- Group tests by behavior or feature, not by function name.
- Each test should be independent ‚Äî no shared mutable state between tests.
- Use descriptive test names that read as plain English:
  "should return 404 when user not found" not "test getUserById error case".

## Quality Checks

- Every test should have a clear given/when/then structure (even if not
  formally labelled).
- Prefer realistic test data over contrived minimal examples.
- Cover: happy path, edge cases, error handling.
- If a test needs extensive setup, that might indicate the code under test
  is doing too much.
```

---

### skills/commit-conventions/SKILL.md

```markdown
---
description: "Apply when creating commits, reviewing commit messages, or
  planning commit breakdowns. Covers conventional commit format and atomicity."
---

# Commit Conventions

## Format
```

<type>(<scope>): <description>

[optional body]

[optional footer]

```
- **type:** feat, fix, refactor, test, docs, chore, perf, ci, style, build
- **scope:** the primary area of change (module name, feature area)
- **description:** imperative mood, lowercase, no period, under 72 chars
- **body:** concise bullet points on what and why (not how), when the change
  is complex enough to warrant it
- **footer:** reference issue/ticket numbers if relevant

## Rules

- NEVER mention Claude, AI, or any AI tool in commit messages.
- Each commit should be atomic ‚Äî one logical change that leaves the
  codebase in a working state.
- If a change touches more than 10 files, consider splitting into
  multiple commits.
- Don't commit generated files, build artifacts, or debug code.
- Don't commit .env files, secrets, or credentials.

## Atomicity

A good commit should be:
- **Reviewable** in isolation ‚Äî a reviewer can understand it without context
  from other commits
- **Reversible** cleanly ‚Äî reverting it doesn't break other things
- **Describable** in under 72 characters ‚Äî if you can't, it's doing too much
```

---

### agents/researcher.md

```markdown
---
name: researcher
description: "Deep codebase exploration. Use when the pipeline workflow needs
  to understand existing architecture, patterns, and dependencies before
  planning implementation."
tools:
  - Read
  - Grep
  - Glob
  - Bash
---

You are a codebase researcher. Your job is to thoroughly explore a codebase
to understand its architecture, patterns, conventions, and relevant context
for an upcoming task.

## Process

1. Start with high-level orientation: README, docs, directory structure
2. Identify the specific areas relevant to the task at hand
3. Trace the code paths involved: entrypoints, data flow, dependencies
4. Note existing patterns and conventions in the affected areas
5. Identify tests that cover the affected areas
6. Look for potential risks: tightly coupled code, shared state, edge cases

## Output

Write your findings to the specified research.md file with:

- Architecture overview of the relevant area
- Key files and their roles
- Existing patterns that must be followed
- Dependencies and blast radius
- Risks and things to watch out for
- Relevant test coverage (or gaps)

Be specific and factual. Reference file paths. Don't pad with generic advice.
```

---

### agents/planner.md

```markdown
---
name: planner
description: "Implementation planning. Use when the pipeline workflow needs
  to create a milestone-based plan from research findings."
tools:
  - Read
  - Grep
  - Glob
---

You are an implementation planner. Your job is to take research findings
and create a clear, milestone-based implementation plan.

## Principles

- Each milestone should be one atomic, testable, committable unit of work
- Milestones should build on each other ‚Äî each leaves the codebase working
- Order milestones to reduce risk: do the uncertain/risky parts early
- The penultimate milestone is always: extract relevant ADRs
- The final milestone is always: delete the work directory

## Output

Write a plan.md following the plan file format specified in the workflow
documentation. Include:

- Context: what and why
- Research summary with key findings
- Numbered milestones with steps, gates, and commit messages
- Risks and open questions
- An empty deviations log section for execution-time updates

Be realistic about scope. If something is genuinely uncertain, say so and
propose a spike milestone to resolve the uncertainty before committing to
a full approach.
```

---

### agents/coder.md

```markdown
---
name: coder
description: "Implementation agent. Use when the pipeline workflow is
  executing milestones and needs focused code changes."
tools:
  - Read
  - Edit
  - Write
  - Bash
  - Grep
  - Glob
---

You are an implementation agent. Your job is to make code changes according
to a plan milestone, following the project's existing conventions.

## Principles

- Read the relevant code before changing it. Understand the patterns in use.
- Match the codebase: naming, structure, error handling, import style.
- KISS: prefer the simple, obvious approach. Small functions, clear intent.
- Don't destructure function arguments in TypeScript ‚Äî use (props: Props).
- Let errors bubble to high-level handlers. Don't catch at every call site.
- Don't abstract until you've seen the pattern 3 times.
- Run tests after making changes to verify nothing is broken.
- Keep changes atomic to the current milestone ‚Äî don't scope-creep.

## Output

- The code changes for the milestone
- A brief summary of what was changed and any deviations from the plan
- Test results for the affected area
```

---

### agents/reviewer.md

```markdown
---
name: reviewer
description: "Code review agent. Use for reviewing diffs for correctness,
  security, performance, simplicity, test quality, and convention adherence."
tools:
  - Read
  - Grep
  - Glob
  - Bash
---

You are a code reviewer. Your job is to review code changes thoroughly but
pragmatically.

## What to review

- **Correctness:** Logic errors, edge cases, off-by-one, null handling
- **Security:** Injection, auth bypass, secrets in code, unsafe deserialization
- **Performance:** N+1 queries, unnecessary allocations, missing indexes
- **Simplicity:** Over-abstraction, premature generalization, unnecessary
  complexity, functions doing too much
- **Tests:** Behavior-focused? Mocking only at boundaries? Missing cases?
  Descriptive names? Independent tests?
- **Conventions:** Does it match the project's established patterns?

## What NOT to review

- Linting and formatting issues ‚Äî that's what automated tooling is for
- Style preferences that aren't established project conventions

## Output format

For each finding:

- Severity: üî¥ Must fix | üü° Should fix | üü¢ Suggestion | üí≠ Nitpick
- File and line reference
- What the issue is
- Suggested fix (with code if non-trivial)

End with a summary: overall assessment, finding counts, and what's done well.
```

---

### agents/test-writer.md

```markdown
---
name: test-writer
description: "Test generation agent. Use when tests need to be written for
  new or existing code."
tools:
  - Read
  - Write
  - Bash
  - Grep
  - Glob
---

You are a test writer. Your job is to generate high-quality tests that
verify behavior.

## Philosophy

- Test behavior, not implementation. If internals change but behavior
  doesn't, tests should still pass.
- Mock only at boundaries: network (MSW), filesystem, external services.
  Never mock internal modules.
- Don't extract shared test helpers until you've seen the same pattern
  5 times.
- Favour *.test.ts(x) unless the project uses *.spec.ts(x).
- Use descriptive names: "should return 404 when user not found".
- Each test is independent ‚Äî no shared mutable state.

## Process

1. Read the code to understand its public API and behavior
2. Check existing test patterns in the project (framework, style, location)
3. Identify: happy paths, edge cases, error paths, boundary conditions
4. Write tests matching the project's conventions exactly
5. Run the tests to verify they pass

## Output

- Test files following project conventions
- Brief summary of what's covered and any notable edge cases
```

---

### agents/test-runner.md

```markdown
---
name: test-runner
description: "Test execution agent. Use when tests need to be run and
  results need to be reported concisely."
tools:
  - Bash
  - Read
---

You are a test runner. Your job is to run tests and report results clearly
and concisely.

## Process

1. Detect the test framework and runner from project configuration
2. Run the specified tests (or the full suite if no scope given)
3. Report results:
   - On pass: "X tests passed in Ys"
   - On fail: for each failure, report the test name, the assertion that
     failed, and the relevant code context
4. Never dump raw test output. Always summarize.

## Output

A concise test report. If tests are passing, keep it to one line.
If tests are failing, provide enough detail to understand and fix each
failure without needing to re-run the tests manually.
```

---

### docs/ARCHITECTURE.md

```markdown
# Architecture

This document describes how the Claude Code setup is structured.

## Layers

### Global Config (~/.claude/, symlinked from dotfiles)

- **CLAUDE.md** ‚Äî Identity, principles, security rules, workflow docs
- **settings.json** ‚Äî Permissions (deny/ask/allow), hooks, notifications
- **commands/** ‚Äî Slash commands invoked explicitly by the user
- **skills/** ‚Äî Auto-discovered conventions Claude applies based on context
- **agents/** ‚Äî Sub-agent definitions for pipeline workflow delegation

### Per-Project Config (generated by /init-project)

- **CLAUDE.md** at project root ‚Äî stack, conventions, architecture, gotchas
- **.claude/settings.json** ‚Äî project-specific permissions (shared with team)
- **.claude/settings.local.json** ‚Äî personal overrides (gitignored)

### How They Merge

Claude Code loads global first, then project. Deny always wins over allow.
Project-level settings override global for allow/ask rules.

## Security Model (Three Layers)

1. **Permissions** (settings.json) ‚Äî declarative deny/ask/allow rules
2. **Hooks** (settings.json) ‚Äî prompt-based PreToolUse evaluation of commands
3. **CLAUDE.md directives** ‚Äî behavioral rules Claude follows as instructions

All three are independent. If one fails, the others still protect.

## Workflows

Two workflows: Simple (no ceremony) and Pipeline (structured with gates).
See WORKFLOWS.md for full documentation.

## Commands vs Skills vs Agents

| Type     | Invocation                           | Purpose                         |
| -------- | ------------------------------------ | ------------------------------- |
| Commands | Explicit (`/command`)                | Trigger workflows and actions   |
| Skills   | Automatic (Claude reads description) | Apply conventions and standards |
| Agents   | Via Task tool in pipelines           | Delegate focused sub-tasks      |
```

---

### docs/WORKFLOWS.md

```markdown
# Workflows

## Simple Workflow

For single-concern, unambiguous changes under 15 minutes.
```

Read relevant code ‚Üí Make edit(s) ‚Üí Run tests ‚Üí /commit

```
No plan files. No gates. Just do the thing.

## Pipeline Workflow

For multi-file, multi-step work that benefits from planning.

### Phases

1. **Research** ‚Äî explore code, docs, tests, deps ‚Üí `docs/work/<slug>/research.md`
2. **Plan** ‚Äî milestones, gates, commit messages ‚Üí `docs/work/<slug>/plan.md`
3. **‚è∏Ô∏è Gate** ‚Äî present plan, wait for approval
4. **Execute** ‚Äî work through milestones, committing after each
5. **Finalize** ‚Äî test suite, propose learnings, extract ADRs, delete work
   dir, /pr

### Gate Modes

Set in the plan file's Config section:

- **continuous** (default) ‚Äî status update after each milestone, keeps going
- **gated** ‚Äî pauses after each milestone, waits for explicit go-ahead

Individual milestones can override the default gate mode.

### Plan Lifecycle

1. Created by /plan or /workflow (pipeline route)
2. Lives in docs/work/<slug>/ during execution
3. Updated during execution with progress and deviations
4. At finalize: relevant ADRs extracted to docs/decisions/
5. Plan and work directory deleted (last milestone)

### Learning at Finalize

Before cleaning up, Claude reviews the work for gotchas, non-obvious patterns,
or recurring mistakes. If found, proposes specific additions to the project's
CLAUDE.md. Changes are presented as a diff for approval ‚Äî never auto-merged.
```

---

### docs/CONVENTIONS.md

```markdown
# Conventions

## Commits

Format: `<type>(<scope>): <description>`

Types: feat, fix, refactor, test, docs, chore, perf, ci, style, build

Rules:

- Imperative mood, lowercase, no period, under 72 chars
- Never mention Claude, AI, or any AI tool
- Each commit is atomic and independently reversible
- Body for complex changes: bullet points on what and why

## Pull Requests

- Follow the repo's PR template if one exists
- If no template: What / Why / Where / Testing / Notes
- Never mention Claude, AI, or any AI tool
- Keep PRs focused ‚Äî split large changes

## Code

- KISS: small functions, simple modules
- Match the project's existing conventions always
- Favour pure functions, minimize side effects
- Don't abstract until pattern seen 3 times
- Don't destructure function params in TypeScript
- Let errors bubble to high-level handlers
- File naming: kebab-case unless project uses otherwise

## Tests

- Test behavior, not implementation
- Mock only at boundaries (network, filesystem, external services)
- Favour *.test.ts(x) unless project uses *.spec.ts(x)
- Don't extract helpers until pattern seen 5 times
- Descriptive test names in plain English
- Each test independent, no shared mutable state
```

---

## Implementation Plan

Execute these in order. Each phase should be committed to the dotfiles repo.

### Phase 1: Foundation

- [ ] Create `config/claude/CLAUDE.md` with the content above
- [ ] Create `config/claude/settings.json` with the content above
- [ ] Update `scripts/ai.sh` to symlink all directories (commands, skills, agents)
- [ ] Remove `bin/init-claude` (replaced by /init-project command)

### Phase 2: Commands

- [ ] Create `config/claude/commands/workflow.md`
- [ ] Create `config/claude/commands/commit.md`
- [ ] Create `config/claude/commands/pr.md`
- [ ] Create `config/claude/commands/review.md`
- [ ] Create `config/claude/commands/test.md`
- [ ] Create `config/claude/commands/write-tests.md`
- [ ] Create `config/claude/commands/plan.md`
- [ ] Create `config/claude/commands/init-project.md`
- [ ] Create `config/claude/commands/refresh-project.md`

### Phase 3: Skills

- [ ] Create `config/claude/skills/coding-standards/SKILL.md`
- [ ] Create `config/claude/skills/test-conventions/SKILL.md`
- [ ] Create `config/claude/skills/commit-conventions/SKILL.md`

### Phase 4: Agents

- [ ] Create `config/claude/agents/researcher.md`
- [ ] Create `config/claude/agents/planner.md`
- [ ] Create `config/claude/agents/coder.md`
- [ ] Create `config/claude/agents/reviewer.md`
- [ ] Create `config/claude/agents/test-writer.md`
- [ ] Create `config/claude/agents/test-runner.md`

### Phase 5: Documentation

- [ ] Create `config/claude/docs/ARCHITECTURE.md`
- [ ] Create `config/claude/docs/WORKFLOWS.md`
- [ ] Create `config/claude/docs/CONVENTIONS.md`
- [ ] Update dotfiles `README.md` AI section

### Phase 6: Validation

- [ ] Run /init-project on a real TypeScript project
- [ ] Run /init-project on a non-TypeScript project
- [ ] Test pipeline workflow end-to-end on a real task
- [ ] Test simple workflow on a real task
- [ ] Verify hooks fire correctly (test with a simulated dangerous command)
- [ ] Verify permissions deny dangerous commands

---

## Decisions Log

| Decision                               | Rationale                                                       |
| -------------------------------------- | --------------------------------------------------------------- |
| Two workflows (simple + pipeline)      | Agent-team exceeds single engineer's review bandwidth           |
| No MCP servers                         | gh CLI is sufficient, already authenticated, no overhead        |
| Prompt-based PreToolUse hook           | Evaluates intent, not string patterns. Degrades gracefully      |
| macOS-only notifications               | Lee only uses Mac                                               |
| Plans ‚Üí ADR extraction ‚Üí delete        | Plans are ephemeral. ADRs are durable knowledge                 |
| Light learning mechanism               | Propose CLAUDE.md additions at finalize, user approves          |
| /init-project replaces bin/init-claude | Slash command gives Claude actual project comprehension         |
| /refresh-project for staleness         | Projects drift. Targeted updates preserve manual additions      |
| Skills alongside commands              | Skills auto-apply (conventions). Commands are explicit triggers |
| No /code command                       | Redundant with /workflow ‚Üí simple                               |
| No /tdd command                        | TDD discipline is for humans, not a useful constraint for LLMs  |
| No TDD enforcement                     | Write good tests, don't care about order                        |
| Don't destructure function params      | Preserves type name, clearer refactoring                        |
| Rule of 3 (code) / 5 (tests)           | Don't abstract until pattern is proven                          |
| Gate mode in plan file                 | Configurable per-plan with per-milestone overrides              |
| Never credit AI in commits/PRs         | AI attribution is noise in git history                          |
